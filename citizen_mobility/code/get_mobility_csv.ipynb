{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Citywide_Mobility_Survey_-_Trip_Survey_2019.csv')\n",
    "df = pd.read_csv('Citywide_Mobility_Survey_-_Trip_Survey_2019.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#筛选需要的字段\n",
    "select_cols = ['person_id','person_num','day_num','trip_id','trip_num','trip_duration','trip_distance','o_purpose','o_purpose_category','d_purpose','d_purpose_category','num_non_hh_travelers','num_hh_travelers',\"num_travelers\",\"mode_type\",\"mode_1\",\"mode_2\",\"mode_3\",\"mode_4\",\"driver\",\"park_location\",\"park_pay\",\"park_cost\",\"used_transit\",\"transit_access\",\"taxi_cost\",\"taxi_cost_amount\",\"bike_park_location\"]\n",
    "select_df_data = df[select_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_cols_1019 = ['person_id','person_num','travel_data_dow','d_purpose','d_purpose_category']\n",
    "selected_data_1019 = df[select_cols_1019]\n",
    "selected_data_1019.to_csv('test_data.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(select_df_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_df_data.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select_df_data.isnull().sum()\n",
    "select_df_data[select_df_data.isnull().values==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "import tensorboard\n",
    "from tensorflow import feature_column\n",
    "from tensorflow.keras import layers,Sequential\n",
    "from tensorflow.keras.layers import DenseFeatures,Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#通过sklearn-train_test_split划分数据集测试集验证集\n",
    "train_data,test_data = train_test_split(select_df_data,test_size=0.2)\n",
    "train_data,val_data=train_test_split(train_data,test_size=0.2)\n",
    "print(len(train_data), '训练数据')\n",
    "print(len(val_data), '验证数据 ')\n",
    "print(len(test_data), '测试数据')\n",
    "print(type(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#将dataframe存储为csv文件\n",
    "\n",
    "train_data.to_csv('train_data.csv')\n",
    "val_data.to_csv('val_data.csv')\n",
    "test_data.to_csv('test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tensorflow能识别的dataset格式\n",
    "def get_dataset(df,shuffle=True,batch_size=32):\n",
    "    df=df.copy()\n",
    "    labels=df.pop('o_purpose')\n",
    "    ds = tf.data.Dataset.from_tensor_slices((dict(df),labels))\n",
    "    \n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(buffer_size=len(df))\n",
    "    ds = ds.batch(batch_size)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 5\n",
    "train_ds = get_dataset(train_data,batch_size=batch_size)\n",
    "val_ds = get_dataset(val_data,shuffle=False,batch_size=batch_size)\n",
    "test_ds = get_dataset(test_data,shuffle=False,batch_size=batch_size)\n",
    "print(type(train_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#分离特征值和标签\n",
    "ndarray_data = select_df_data.values\n",
    "feature = ndarray_data[:,1:]\n",
    "label = ndarray_data[:,0]\n",
    "print(ndarray_data)\n",
    "print(feature)\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#特征值标准处理化\n",
    "from sklearn import preprocessing\n",
    "minmax_scale = preprocessing.MinMaxScaler(feature_range=(0, 1))\n",
    "norm_features = minmax_scale.fit_transform(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义数据预处理函数\n",
    "def pre_data(df_data):\n",
    "    df = df_data.drop(df_data['park_cost'], axis=1)\n",
    "    df = df_data\n",
    "    \n",
    "    ndarray_data = df.values\n",
    "\n",
    "    features = ndarray_data[:, 1:]\n",
    "    label = ndarray_data[:, 0]\n",
    "    \n",
    "    minmax_scale =preprocessing.MinMaxScaler(feature_range=(0,1))\n",
    "    norm_features=minmax_scale.fit_transform(features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_df_data[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_data(select_df_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_df_data = select_df_data.sample(frac=1)\n",
    "\n",
    "x_data, y_data = pre_data(shuffled_df_data)\n",
    "\n",
    "train_size = int(len(x_data)*0.8)\n",
    "\n",
    "x_train = x_data[:train_size]\n",
    "y_train = y_data[:train_size]\n",
    "\n",
    "x_test = x_data[train_size:]\n",
    "y_test = y_data[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#特征值的标签作为输入要素\n",
    "for feature_batch,label_batch in train_ds.take(1):\n",
    "    feature = list(feature_batch.keys())\n",
    "    print('feature list:',feature)\n",
    "    print('A batch of targets:',label_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for header in feature:\n",
    "    print(header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#遍历特征列表feature,拿到每一个特征值，\n",
    "# 使用feature_column.numeric_column(header)将所有类型转为数值类型，\n",
    "# 在通过DenseFeatures()转为Dense类型，作为输入层\n",
    "feature_columns = []\n",
    "\n",
    "for header in feature:\n",
    "    feature_columns.append(tf.feature_column.numeric_column(header))\n",
    "feature_layer = DenseFeatures(feature_columns)\n",
    "#print(feature_layer(next(iter(train_ds))[0]).numpy())\n",
    "#\n",
    "#print(type(feature_column.numeric_column(header)))  # 可以看到转换类型\n",
    "#<class 'tensorflow.python.feature_column.feature_column_v2.NumericColumn'>\n",
    "#print(type(feature_layer))\n",
    "#<class 'tensorflow.python.keras.feature_column.dense_features_v2.DenseFeatures'>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tensorflow    tf.data.experimental.make_csv_dataset \n",
    "def get_dataset(csv_path):\n",
    "    return tf.data.experimental.make_csv_dataset(\n",
    "        csv_path,\n",
    "        batch_size=12,\n",
    "        label_name='o_purpose',\n",
    "        na_value='?',\n",
    "        num_epochs=1,\n",
    "        ignore_errors=True\n",
    "    )\n",
    "    \n",
    "train_set = get_dataset('train_data.csv'),\n",
    "test_set = get_dataset('test_data.csv'),\n",
    "#feats,lbls = next(iter(test_set))\n",
    "#print('features =', feats)\n",
    "#print('labels =', lbls)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LSTM\n",
    "from tensorflow import keras\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Embedding(output_dim=32,\n",
    "                                 input_dim=28,\n",
    "                                 input_length=28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LSTM\n",
    "#全连接层\n",
    "model.add(keras.layers.Bidirectional(keras.layers.LSTM(units=8)))\n",
    "model.add(keras.layers.Dense(units=32,activation='relu'))\n",
    "model.add(keras.layers.Dropout(0.3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LSTM\n",
    "#输出层\n",
    "model.add(keras.layers.Dense(units=2,activation='softmax'))\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#模型训练 告知训练时使用的优化器，损失函数，准确率评估标准\n",
    "#one-hot多分类模型 损失函数用categoricalcrossentropy\n",
    "#不是多分类的one-hot 编码模型 损失函数用sparse_categorical_crossentropy\n",
    "#二分类用binary_crossentropy\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(0.003),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#模型训练\n",
    "train_history = model.fit(train_data,\n",
    "                          validation_split=0.2,\n",
    "                          epochs=100,\n",
    "                          batch_size=40,\n",
    "                          verbose=2\n",
    "                          )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as plt\n",
    "\n",
    "def visu_train_history(train_history,train_metric,validation_metric):\n",
    "    plt.plot(train_history.history[train_metric])\n",
    "    plt.plot(train_history.history[validation_metric])\n",
    "    plt.title('Train History')\n",
    "    plt.ylabel('train_metric')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train','validation'],loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#建立keras序列模型\n",
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "model.add(tf.keras.layers.Dense(\n",
    "                                units=64,\n",
    "                                input_dim=7,\n",
    "                                use_bias=True,\n",
    "                                kernel_initializer='uniform',\n",
    "                                bias_initializer='zero',\n",
    "                                activation='relu'\n",
    "))\n",
    "model.add(tf.keras.layers.Dense(units=32,\n",
    "                                activation='sigmoid'))\n",
    "model.add(tf.keras.layers.Dense(units=1,\n",
    "                                activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#模型设置\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(0.003),\n",
    "              loss='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#模型训练\n",
    "train_history = model.fit(x=train_set,\n",
    "                          y=train_set,\n",
    "                          validation_split=0.2,\n",
    "                          epochs=100,\n",
    "                          batch_size=40,\n",
    "                          verbose=2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cf1d9465f6502f177b365be3304d09fdeffdb2bc4d9e067aaaa01fb948a8cbd7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
